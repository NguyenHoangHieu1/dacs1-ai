{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db65b28-c525-4766-a0b1-7cbbaac3a560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang xử lý 4904 video bằng 12 core...\n",
      "Xử lý xong, tổng số ảnh: 24427\n",
      "Đã lưu batch 1 với 1000 ảnh.\n",
      "Đã lưu batch 2 với 1000 ảnh.\n",
      "Đã lưu batch 3 với 1000 ảnh.\n",
      "Đã lưu batch 4 với 1000 ảnh.\n",
      "Đã lưu batch 5 với 1000 ảnh.\n",
      "Đã lưu batch 6 với 1000 ảnh.\n",
      "Đã lưu batch 7 với 1000 ảnh.\n",
      "Đã lưu batch 8 với 1000 ảnh.\n",
      "Đã lưu batch 9 với 1000 ảnh.\n",
      "Đã lưu batch 10 với 1000 ảnh.\n",
      "Đã lưu batch 11 với 1000 ảnh.\n",
      "Đã lưu batch 12 với 1000 ảnh.\n",
      "Đã lưu batch 13 với 1000 ảnh.\n",
      "Đã lưu batch 14 với 1000 ảnh.\n",
      "Đã lưu batch 15 với 1000 ảnh.\n",
      "Đã lưu batch 16 với 1000 ảnh.\n",
      "Đã lưu batch 17 với 1000 ảnh.\n",
      "Đã lưu batch 18 với 1000 ảnh.\n",
      "Đã lưu batch 19 với 1000 ảnh.\n",
      "Đã lưu batch 20 với 1000 ảnh.\n",
      "Đã lưu batch 21 với 1000 ảnh.\n",
      "Đã lưu batch 22 với 1000 ảnh.\n",
      "Đã lưu batch 23 với 1000 ảnh.\n",
      "Đã lưu batch 24 với 1000 ảnh.\n",
      "Đã lưu batch 25 với 427 ảnh.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# Cấu hình thư mục\n",
    "data_dir = './'  # Thư mục chứa dữ liệu\n",
    "output_dir = './processed_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Bản đồ cảm xúc\n",
    "emotions_map = {\n",
    "    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',\n",
    "    '05': 'angry', '06': 'fear', '07': 'disgust', '08': 'surprise'\n",
    "}\n",
    "\n",
    "# Lấy faces ngẫu nhiên từ video\n",
    "def extract_random_faces(video_path, max_faces=10, frame_size=(64, 64), sample_frames=5):\n",
    "    faces = []\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames < 2:\n",
    "        cap.release()\n",
    "        return faces\n",
    "\n",
    "    frame_indices = sorted(random.sample(range(total_frames), min(sample_frames, total_frames)))\n",
    "\n",
    "    for i in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        small = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY)\n",
    "        faces_detected = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "        if len(faces_detected) > 0:\n",
    "            (x, y, w, h) = max(faces_detected, key=lambda rect: rect[2] * rect[3])\n",
    "            x, y, w, h = x*2, y*2, w*2, h*2\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, frame_size)\n",
    "            faces.append(face)\n",
    "        if len(faces) >= max_faces:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    return faces\n",
    "\n",
    "# Hàm xử lý 1 video (dùng cho multiprocessing)\n",
    "def process_video(args):\n",
    "    subfolder_path, file = args\n",
    "    emotion_code = file.split('-')[2]\n",
    "    emotion = emotions_map.get(emotion_code)\n",
    "    if not emotion:\n",
    "        return []\n",
    "\n",
    "    video_path = os.path.join(subfolder_path, file)\n",
    "    faces = extract_random_faces(video_path)\n",
    "\n",
    "    results = []\n",
    "    for idx, face in enumerate(faces):\n",
    "        out_name = f\"{file.replace('.mp4', '')}_frame{idx}.jpg\"\n",
    "        output_path = os.path.join(output_dir, out_name)\n",
    "        if not os.path.exists(output_path):\n",
    "            cv2.imwrite(output_path, cv2.cvtColor(face, cv2.COLOR_RGB2BGR))\n",
    "        results.append((output_path, emotion))\n",
    "    return results\n",
    "\n",
    "# Tìm tất cả video cần xử lý\n",
    "all_videos = []\n",
    "for actor_folder in os.listdir(data_dir):\n",
    "    actor_path = os.path.join(data_dir, actor_folder)\n",
    "    if os.path.isdir(actor_path) and ('Video_Speech_Actor_' in actor_folder or 'Video_Song_Actor_' in actor_folder):\n",
    "        for subfolder in os.listdir(actor_path):\n",
    "            subfolder_path = os.path.join(actor_path, subfolder)\n",
    "            if os.path.isdir(subfolder_path) and subfolder.startswith('Actor_'):\n",
    "                for file in os.listdir(subfolder_path):\n",
    "                    if file.endswith('.mp4'):\n",
    "                        all_videos.append((subfolder_path, file))\n",
    "\n",
    "print(f\"Đang xử lý {len(all_videos)} video bằng {cpu_count()} core...\")\n",
    "\n",
    "# Dùng multiprocessing để tăng tốc\n",
    "all_results = []\n",
    "with Pool(processes=cpu_count()) as pool:\n",
    "    for result in pool.imap_unordered(process_video, all_videos):\n",
    "        all_results.extend(result)\n",
    "\n",
    "print(f\"Xử lý xong, tổng số ảnh: {len(all_results)}\")\n",
    "\n",
    "# Chia nhỏ và lưu ra nhiều file pkl\n",
    "batch_size = 1000\n",
    "for i in range(0, len(all_results), batch_size):\n",
    "    batch = all_results[i:i+batch_size]\n",
    "    image_paths, labels = zip(*batch)\n",
    "    with open(f\"image_paths_labels_batch{i//batch_size + 1}.pkl\", \"wb\") as f:\n",
    "        pickle.dump((image_paths, labels), f)\n",
    "    print(f\"Đã lưu batch {i//batch_size + 1} với {len(batch)} ảnh.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "619875d0-a867-4b7b-9191-cf84b759a404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2555100c-d1e7-4fe3-9ad9-6935be3d4675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 24427 images from 8 classes.\n",
      "Epoch 1/50, Loss: 847.5332, Acc: 39.02%\n",
      "Epoch 2/50, Loss: 587.6785, Acc: 59.39%\n",
      "Epoch 3/50, Loss: 481.7855, Acc: 66.80%\n",
      "Epoch 4/50, Loss: 414.0335, Acc: 71.90%\n",
      "Epoch 5/50, Loss: 360.2077, Acc: 75.34%\n",
      "Epoch 6/50, Loss: 324.8477, Acc: 77.78%\n",
      "Epoch 7/50, Loss: 297.8691, Acc: 79.56%\n",
      "Epoch 8/50, Loss: 275.0000, Acc: 80.92%\n",
      "Epoch 9/50, Loss: 256.2184, Acc: 82.34%\n",
      "Epoch 10/50, Loss: 244.5457, Acc: 82.88%\n",
      "Epoch 11/50, Loss: 227.4775, Acc: 84.17%\n",
      "Epoch 12/50, Loss: 218.5861, Acc: 84.67%\n",
      "Epoch 13/50, Loss: 204.9960, Acc: 85.48%\n",
      "Epoch 14/50, Loss: 196.7040, Acc: 85.97%\n",
      "Epoch 15/50, Loss: 195.6734, Acc: 86.29%\n",
      "Epoch 16/50, Loss: 181.1172, Acc: 87.03%\n",
      "Epoch 17/50, Loss: 173.6123, Acc: 87.71%\n",
      "Epoch 18/50, Loss: 167.7726, Acc: 88.05%\n"
     ]
    }
   ],
   "source": [
    "# train_from_images.py\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# Load tất cả file .pkl chứa ảnh đã tách\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for filename in os.listdir():\n",
    "    if filename.startswith(\"image_paths_labels_batch\") and filename.endswith(\".pkl\"):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            paths, lbls = pickle.load(f)\n",
    "            image_paths.extend(paths)\n",
    "            labels.extend(lbls)\n",
    "\n",
    "print(f\"✅ Loaded {len(image_paths)} images from {len(set(labels))} classes.\")\n",
    "\n",
    "# Encode nhãn\n",
    "le = LabelEncoder()\n",
    "labels_encoded = torch.tensor(le.fit_transform(labels), dtype=torch.long)\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Dataset class\n",
    "class PreprocessedDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.image_paths[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[idx]\n",
    "\n",
    "# Train/test split\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    image_paths, labels_encoded, test_size=0.3, random_state=42, stratify=labels_encoded\n",
    ")\n",
    "\n",
    "train_dataset = PreprocessedDataset(train_paths, train_labels, transform)\n",
    "test_dataset = PreprocessedDataset(test_paths, test_labels, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# CNN model\n",
    "class FacialEmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*8*8, 64), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = FacialEmotionCNN(num_classes=len(le.classes_)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, loader, criterion, optimizer, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total, correct, running_loss = 0, 0, 0\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Acc: {100*correct/total:.2f}%\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"facial_emotion_cnn.pth\")\n",
    "    print(\"✅ Model saved to facial_emotion_cnn.pth\")\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"🎯 Test Accuracy: {100*correct/total:.2f}%\")\n",
    "\n",
    "# Run\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
